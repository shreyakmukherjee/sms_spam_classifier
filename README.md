# ğŸ“© SMS Spam Classifier

A simple and effective machine learning app that classifies SMS messages as **Spam** or **Not Spam** using Natural Language Processing (NLP) and the Naive Bayes algorithm. Built with â¤ï¸ using **Streamlit**, **scikit-learn**, and **NLTK**.

---

## ğŸš€ Live Demo

ğŸ‘‰ [Click here to open the app](https://smsspamclassifier-edwnnvw2ovwec7d8vgp9dx.streamlit.app)
*(Replace with your deployed Streamlit URL)*

---

## ğŸ§  Features

âœ… Predict whether a message is spam or not  
âœ… Clean NLP preprocessing pipeline  
âœ… Fast and lightweight  
âœ… Trained on real-world SMS dataset  
âœ… Easy-to-use Streamlit interface  

---

## ğŸ“‚ Project Files

```
ğŸ“ SMS_Spam_Classifier/
â”‚
â”œâ”€â”€ app.py                # Streamlit application
â”œâ”€â”€ SMS_spam_classifier.ipynb  # Notebook for EDA and model training
â”œâ”€â”€ model.pkl             # Trained Naive Bayes model
â”œâ”€â”€ vectorizer.pkl        # Trained TF-IDF vectorizer
â”œâ”€â”€ spam.csv              # Original SMS dataset
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ .devcontainer/        # VS Code dev container config (optional)
```

---

## ğŸ›  Installation

### ğŸ”— Clone the Repository

```bash
git clone https://github.com/your-username/sms_spam_classifier.git
cd sms_spam_classifier
```

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

### â–¶ Run the App

```bash
streamlit run app.py
```

---

## ğŸ“Š Dataset

ğŸ“ `spam.csv`  
- Source: [Kaggle - SMS Spam Collection](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)  
- 5,572 SMS messages labeled as **spam** or **ham** (not spam)

---

## ğŸ’¡ How It Works

1. âœ‚ï¸ **Preprocessing**: Lowercasing, stopword removal, stemming  
2. ğŸ§  **Vectorization**: TF-IDF transforms text into numerical features  
3. ğŸ¤– **Model**: Multinomial Naive Bayes trained on processed data  
4. ğŸŒ **Interface**: Built using Streamlit for real-time predictions  

---

## ğŸ—ï¸ System Architecture

### ğŸ” 1. Data Ingestion

- **Source**: `spam.csv`  
- **Encoding**: ISO-8859-1  
- **Initial Shape**: 5,572 rows Ã— 5 columns

---

### ğŸ§¹ 2. Data Cleaning

- Dropped columns: `Unnamed: 2`, `Unnamed: 3`, `Unnamed: 4`  
- Renamed columns: `v1 â†’ target`, `v2 â†’ text`  
- Encoded labels: `ham â†’ 0`, `spam â†’ 1`  
- Removed 403 duplicates  
- Final shape: 5,169 rows Ã— 2 columns

---

### ğŸ› ï¸ 3. Feature Engineering

**Derived Features:**

| Feature         | Description                              |
|----------------|------------------------------------------|
| `num_characters` | Character count per message              |
| `num_words`      | Word count per message                   |
| `num_sentences`  | Sentence count (split by `.`)            |

**Text Transformation:**

- Lowercasing  
- Tokenization  
- Stopword Removal  
- Stemming with Porter Stemmer

---

### ğŸ“Š 4. Exploratory Data Analysis (EDA)

- **Class Balance**:  
  - 87.4% Ham (4,516)  
  - 12.6% Spam (653)  

- **Key Insights**:  
  - Spam messages are ~95% longer  
  - More words per message in spam  
  - Frequent spam keywords: `free`, `call`, `txt`, `claim`, `prize`  
  - Frequent ham keywords: `go`, `get`, `love`, `good`, `like`

- **Visualizations**:  
  - Label distribution pie chart  
  - Word clouds (spam vs ham)  
  - Top 30 words (bar chart)

---

### ğŸ§  5. Text Vectorization

- **Technique**: TF-IDF  
- **Max Features**: 3,000  
- Converts text into sparse numerical matrix

---

### ğŸ¤– 6. Model Training

**Algorithms Tested**:

- GaussianNB, MultinomialNB, BernoulliNB  
- Logistic Regression, SVC, KNN  
- Decision Tree, Random Forest  
- AdaBoost, GradientBoosting, XGBoost  
- BaggingClassifier, ExtraTrees  

**Validation Strategy**: 80/20 split  
**Primary Metric**: **Precision**

---

### ğŸ“ˆ 7. Model Evaluation

| Model          | Accuracy | Precision |
|----------------|----------|-----------|
| MultinomialNB  | 97.78%   | **1.00**    |
| RandomForest   | 97.78%   | 0.99      |
| ExtraTrees     | 98.16%   | 0.98      |

---

### ğŸ¤ 8. Ensemble Learning

- **Voting Classifier**: (SVC + MNB + ExtraTrees)  
  - Accuracy: 98.16%  
  - Precision: **99.17%**

- **Stacking Classifier**: (Same base + RF meta)  
  - Accuracy: 98.55%  
  - Precision: 96.95%

---

### ğŸ’¾ 9. Model Persistence

- `model.pkl`: Final MultinomialNB model  
- `vectorizer.pkl`: TF-IDF vectorizer (3,000 features)

---

## ğŸ§¾ Component Summary

| Component         | Value                              | Notes                             |
|------------------|------------------------------------|-----------------------------------|
| Dataset Size      | 5,572 â†’ 5,169 rows                 | After removing duplicates         |
| Class Ratio       | 87.4% ham / 12.6% spam             | Slightly imbalanced               |
| Text Pipeline     | Lowercase â†’ Tokenize â†’ Stem        | `transform_text()` function       |
| Vectorizer        | TF-IDF, max_features = 3000        | Custom trained                    |
| Best Base Model   | MultinomialNB                      | Precision = **1.00**              |
| Best Ensemble     | Voting Classifier                  | Precision = 99.17%                |
| Deployment Files  | `model.pkl`, `vectorizer.pkl`      | For Streamlit inference           |

---

## ğŸ” Recommendations

| Area                | Suggestion                                           |
|---------------------|------------------------------------------------------|
| Class Imbalance     | Try SMOTE or under-sampling techniques               |
| Hyperparameter Tuning | Tune `max_features`, test n-gram ranges            |
| Embedding Options   | Test BERT, Sentence Transformers                     |
| Thresholding        | Use probability threshold for precision-recall tradeoff |
| Monitoring          | Track input message patterns for concept drift      |
| Safety              | Add fallback for low-confidence predictions         |

---

## ğŸ” Examples

**ğŸ“¥ Input (Ham):**  
```
Hey, just checking in. Can we meet tomorrow?
```
**âœ… Output:** Not Spam

---

**ğŸ“¥ Input (Spam):**  
```
You've won a free cruise! Click here to claim your prize now.
```
**ğŸš« Output:** Spam

---

## ğŸ›  Tech Stack

- ğŸ Python  
- ğŸ“Š scikit-learn  
- ğŸ”¤ NLTK  
- ğŸ§  TF-IDF Vectorizer  
- ğŸŒ Streamlit  

---

## ğŸ‘¤ Author

- **Shreyak Mukherjee**  
  ğŸ“§ [shreyakmukhrjeedgp@gmail.com](mailto:shreyakmukhrjeedgp@gmail.com)  
  ğŸ”— [LinkedIn](https://www.linkedin.com/in/shreyak-mukherjee-203558275/)  
  ğŸ’» [GitHub](https://github.com/shreyakmukherjee)

---

## ğŸ“„ License

This project is open-source and available under the [MIT License](LICENSE).

---

â­ If you like this project, don't forget to give it a star on GitHub!
